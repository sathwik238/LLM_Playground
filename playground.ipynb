{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "# LLM_Playground\n",
    "\n",
    "A versatile sandbox for exploring and experimenting with Large Language Models (LLMs). \n",
    "This script is part of the LLM_Playground repository and demonstrates how to work with \n",
    "various LLMs, including tasks such as text generation, summarization, Q&A, and more.\n",
    "\n",
    "## Features:\n",
    "- Model experimentation and prompt engineering.\n",
    "- Fine-tuning pre-trained LLMs on custom datasets.\n",
    "- Performance benchmarking with relevant metrics.\n",
    "- Integration examples for real-world applications.\n",
    "\n",
    "## Prerequisites:\n",
    "- Python 3.8 or later.\n",
    "- Required libraries: OpenAI, Hugging Face Transformers, TensorFlow or PyTorch (based on the model).\n",
    "\n",
    "## How to Use:\n",
    "1. Clone the repository: `git clone https://github.com/sathwik238/LLM_Playground.git`\n",
    "2. Install dependencies: `pip install -r requirements.txt`\n",
    "3. Run this script: `playground.ipynb`\n",
    "\n",
    "### Repository Link:\n",
    "[LLM_Playground](https://github.com/sathwik238/LLM_Playground)\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up configuration keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the API key from .env file\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# setting the API key\n",
    "openai.api_key = openai_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Chat - response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression is a statistical method used to model the relationship between a dependent variable and one or more independent variables by fitting a linear equation to the observed data. The goal of linear regression is to find the best-fitting line that describes the relationship between the variables, allowing for the prediction of the dependent variable based on the values of the independent variables. This method is commonly used in various fields, such as economics, finance, and social sciences, to analyze and predict outcomes based on historical data.\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [\n",
    "        { \"role\": \"user\", \"content\": \"What is Linear REgression?\"} # User message\n",
    "\n",
    "    ] \n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-AtjiUWHWO44EXS7ajj7IbxnSL3GT5',\n",
       " 'choices': [{'finish_reason': 'stop',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'message': {'content': 'Linear regression is a statistical method used to model the relationship between a dependent variable and one or more independent variables by fitting a linear equation to the observed data. The goal of linear regression is to find the best-fitting line that describes the relationship between the variables, allowing for the prediction of the dependent variable based on the values of the independent variables. This method is commonly used in various fields, such as economics, finance, and social sciences, to analyze and predict outcomes based on historical data.',\n",
       "    'refusal': None,\n",
       "    'role': 'assistant'}}],\n",
       " 'created': 1737847138,\n",
       " 'model': 'gpt-3.5-turbo-0125',\n",
       " 'object': 'chat.completion',\n",
       " 'service_tier': 'default',\n",
       " 'system_fingerprint': None,\n",
       " 'usage': {'completion_tokens': 99,\n",
       "  'prompt_tokens': 13,\n",
       "  'total_tokens': 112,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### number of tokens to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heart\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [\n",
    "        { \"role\": \"user\", \"content\": \"Listen to your\"}\n",
    "\n",
    "    ] ,\n",
    "    max_tokens=1 # limit the number of tokens to 1\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### number of generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heart;\n",
      " inner voice\n",
      " heart,\n",
      " heart,\n",
      "inner voice\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [\n",
    "        { \"role\": \"user\", \"content\": \"Listen to your\"}\n",
    "\n",
    "    ] ,\n",
    "    max_tokens = 2,\n",
    "    n = 5 # number of completions to generate\n",
    ")\n",
    "\n",
    "for i in range(len(response.choices)):\n",
    "    print(response.choices[i].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " instincts and\n",
      "mind and\n",
      " thoughts and\n",
      " gut\n",
      "\n",
      "you coins\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [\n",
    "        { \"role\": \"user\", \"content\": \"Listen to your\"}\n",
    "\n",
    "    ] ,\n",
    "    max_tokens = 2,\n",
    "    n = 5,\n",
    "    temperature = 2 # 0 is deterministic, 1 is default, 2 is random\n",
    ")\n",
    "\n",
    "for i in range(len(response.choices)):\n",
    "    print(response.choices[i].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI stands for Artificial Intelligence. It's like giving a computer a brain so it can do things that normally need human intelligence, like learning from information, making decisions, and even understanding and responding to language. It's pretty cool because it helps computers do smart things on their own!\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [\n",
    "        { \"role\": \"system\", \"content\": \"you are a AI chat bot who is expected to provide answers to the user queries in a easily understandable manner, like explaining it to an 8 years old child..\"},\n",
    "        { \"role\": \"user\", \"content\": \"what is AI?\"}\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple chat bot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI:  Rohit Sharma is an Indian cricketer who is considered one of the best batsmen in the world. He is also the vice-captain of the Indian national cricket team in limited-overs formats. Rohit is known for his ability to score big runs and has set numerous records in international cricket, including being the only player in history to score three double centuries in One Day Internationals (ODIs).\n",
      "AI:  Is there anything else you would like to know about Rohit Sharma?\n",
      "AI:  Rohit Sharma plays for the Mumbai Indians in the Indian Premier League (IPL). He has been an integral part of the team and has led them to multiple IPL championships as their captain.\n",
      "AI:  Is there anything else you would like to know about Rohit Sharma or any other topic? Feel free to ask!\n",
      "AI:  Thank you for your time. Have a great day!\n",
      "AI:  You're welcome! If you have any more questions in the future, feel free to reach out. Have a wonderful day too!\n",
      "AI:  Goodbye!\n",
      "AI:  Goodbye!\n",
      "AI:  Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    \n",
    "    if user_input.lower() == \"exit\":\n",
    "        break\n",
    "    else:\n",
    "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "        response = openai.chat.completions.create(\n",
    "            model = \"gpt-3.5-turbo\",\n",
    "            messages = messages\n",
    "        )\n",
    "        ai_op = response.choices[0].message.content\n",
    "        print(\"AI: \", ai_op)\n",
    "        messages.append({\"role\": \"system\", \"content\": ai_op})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
